{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eleven-workplace",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [10]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-hotel",
   "metadata": {
    "papermill": {
     "duration": 0.019423,
     "end_time": "2021-03-10T13:16:09.306441",
     "exception": false,
     "start_time": "2021-03-10T13:16:09.287018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ESM Embeddings for NetsurfP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-textbook",
   "metadata": {
    "papermill": {
     "duration": 0.017115,
     "end_time": "2021-03-10T13:16:09.339349",
     "exception": false,
     "start_time": "2021-03-10T13:16:09.322234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook will try using embeddings from facebook researchs esm pre-trained model that uses a deep representation of 650M Unirep50 sequences.\n",
    "\n",
    "https://github.com/facebookresearch/esm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-mozambique",
   "metadata": {
    "papermill": {
     "duration": 0.019005,
     "end_time": "2021-03-10T13:16:09.372177",
     "exception": false,
     "start_time": "2021-03-10T13:16:09.353172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Libraries and pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-player",
   "metadata": {
    "papermill": {
     "duration": 0.016111,
     "end_time": "2021-03-10T13:16:09.401278",
     "exception": false,
     "start_time": "2021-03-10T13:16:09.385167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Download pretrained model** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-scout",
   "metadata": {
    "papermill": {
     "duration": 0.014661,
     "end_time": "2021-03-10T13:16:09.431681",
     "exception": false,
     "start_time": "2021-03-10T13:16:09.417020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Load libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minimal-bacon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T13:16:09.463523Z",
     "iopub.status.busy": "2021-03-10T13:16:09.463115Z",
     "iopub.status.idle": "2021-03-10T13:16:10.266114Z",
     "shell.execute_reply": "2021-03-10T13:16:10.266454Z"
    },
    "papermill": {
     "duration": 0.820044,
     "end_time": "2021-03-10T13:16:10.266593",
     "exception": false,
     "start_time": "2021-03-10T13:16:09.446549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import esm\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "#pip install https://github.com/facebookresearch/esm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-atlanta",
   "metadata": {
    "papermill": {
     "duration": 0.012458,
     "end_time": "2021-03-10T13:16:10.291822",
     "exception": false,
     "start_time": "2021-03-10T13:16:10.279364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-watch",
   "metadata": {
    "papermill": {
     "duration": 0.013763,
     "end_time": "2021-03-10T13:16:10.320692",
     "exception": false,
     "start_time": "2021-03-10T13:16:10.306929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The data is loaded and converted back to aminoacids for the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "psychological-musician",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T13:16:10.358940Z",
     "iopub.status.busy": "2021-03-10T13:16:10.358548Z",
     "iopub.status.idle": "2021-03-10T13:16:10.392279Z",
     "shell.execute_reply": "2021-03-10T13:16:10.392588Z"
    },
    "papermill": {
     "duration": 0.050622,
     "end_time": "2021-03-10T13:16:10.392679",
     "exception": false,
     "start_time": "2021-03-10T13:16:10.342057",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "data_dir = \"../../data/nsp2/training_data/\"\n",
    "\n",
    "datasets = [\n",
    "    (\"train_hhblits\", np.load(data_dir + \"Train_HHblits_small.npz\")),\n",
    "    #(\"CB513_hhblits\", np.load(dir_path + \"CB513_HHblits.npz\")),\n",
    "    #(\"TS115_hhblits\", np.load(dir_path + \"TS115_HHblits.npz\")),\n",
    "    (\"CASP12_HHblits\", np.load(data_dir + \"CASP12_HHblits.npz\")),\n",
    "    \n",
    "    #(\"Train_MMseqs\", np.load(dir_path + \"Train_MMseqs.npz\")),\n",
    "    #(\"CB513_MMseqs\", np.load(dir_path + \"CB513_MMseqs.npz\")),\n",
    "    #(\"TS115_MMseqs\", np.load(dir_path + \"TS115_MMseqs.npz\")),\n",
    "    #(\"CASP12_MMseqs\", np.load(dir_path + \"CASP12_MMseqs.npz\")),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "above-scholar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T13:16:10.427824Z",
     "iopub.status.busy": "2021-03-10T13:16:10.427445Z",
     "iopub.status.idle": "2021-03-10T13:16:10.429383Z",
     "shell.execute_reply": "2021-03-10T13:16:10.429058Z"
    },
    "papermill": {
     "duration": 0.021686,
     "end_time": "2021-03-10T13:16:10.429460",
     "exception": false,
     "start_time": "2021-03-10T13:16:10.407774",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "data_dir = \"/home/projects/ht3_aim/people/erikie/NSPThesis/data/nsp2/training_data\"\n",
    "model_path = (\n",
    "    \"/home/projects/ht3_aim/people/erikie/NSPThesis/models/esm1b_t33_650M_UR50S.pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-prompt",
   "metadata": {
    "papermill": {
     "duration": 0.020861,
     "end_time": "2021-03-10T13:16:10.465608",
     "exception": false,
     "start_time": "2021-03-10T13:16:10.444747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A function converts sparse encoding back to amino acid sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "corresponding-habitat",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T13:16:10.500387Z",
     "iopub.status.busy": "2021-03-10T13:16:10.500002Z",
     "iopub.status.idle": "2021-03-10T13:16:10.501887Z",
     "shell.execute_reply": "2021-03-10T13:16:10.501577Z"
    },
    "papermill": {
     "duration": 0.02311,
     "end_time": "2021-03-10T13:16:10.501969",
     "exception": false,
     "start_time": "2021-03-10T13:16:10.478859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sparse_to_sequence(dataset):\n",
    "    data = []\n",
    "\n",
    "    aa_decode = np.array([\"N\",\"A\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"K\",\"L\",\"M\",\"N\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"V\",\"W\",\"Y\"])\n",
    "\n",
    "    # get the amino acid encoding and apply decode mask\n",
    "    for seq_id in range(dataset.shape[0]):\n",
    "        seq_mask = dataset[seq_id, dataset[seq_id, :, 50] == 1, :20]\n",
    "        aa_idx = np.argmax(seq_mask, axis=1)\n",
    "\n",
    "        aa_sequence = str()\n",
    "        for idx in aa_idx:\n",
    "            aa_sequence += aa_decode[idx]\n",
    "\n",
    "        # store decoded sequence\n",
    "        data.append((\"protein\" + str(seq_id), aa_sequence))\n",
    "    \n",
    "    # remove later\n",
    "    data.append((\"protein_x\", \"N\"*1632))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-signature",
   "metadata": {
    "papermill": {
     "duration": 0.016772,
     "end_time": "2021-03-10T13:16:10.534570",
     "exception": false,
     "start_time": "2021-03-10T13:16:10.517798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Display first sequence to check conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "combined-counter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T13:16:10.568304Z",
     "iopub.status.busy": "2021-03-10T13:16:10.567930Z",
     "iopub.status.idle": "2021-03-10T13:16:12.869006Z",
     "shell.execute_reply": "2021-03-10T13:16:12.869348Z"
    },
    "papermill": {
     "duration": 2.319633,
     "end_time": "2021-03-10T13:16:12.869466",
     "exception": false,
     "start_time": "2021-03-10T13:16:10.549833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('protein0',\n",
       " 'LISNWHNIPQPHRETIRGERQPKDDQKFKHDTPNNHKRQTFCFSPCMKRFNDINTPTITINKNCNPEDTTGRKNIVIQPSKFPGCERNFDFKWSGLINKQNCDCQKRNKGRTWTCPVCVDQTLFCFDQPERSKIRSTDNHVNFHINSDNNTRDDEFKNNEKNCPHGETGRPDKKRQWNCKCNIFQDQNHNICKFNTEKTFHFFIKRCFGQGCTQNNCWCCVRSNRDKFGNFKMFCHKTVMNTKDCNEDKRRLFHQTCNCSKIGPKNKSFCDCQKDKDVGPNKKQFDLNPSHFFFHFPRQKSLKKKPKNGHFPTPNFTVNNNTQDRTNRKK')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_to_sequence(datasets[0][1]['data'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-conflict",
   "metadata": {
    "papermill": {
     "duration": 0.01707,
     "end_time": "2021-03-10T13:16:12.902908",
     "exception": false,
     "start_time": "2021-03-10T13:16:12.885838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ESM1b Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-fault",
   "metadata": {
    "papermill": {
     "duration": 0.017641,
     "end_time": "2021-03-10T13:16:12.939954",
     "exception": false,
     "start_time": "2021-03-10T13:16:12.922313",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The pre-trained model is instantiated with the batch converter that converts the sequences to batch tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "charged-column",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T13:16:12.970918Z",
     "iopub.status.busy": "2021-03-10T13:16:12.970521Z",
     "iopub.status.idle": "2021-03-10T13:16:49.075509Z",
     "shell.execute_reply": "2021-03-10T13:16:49.075821Z"
    },
    "papermill": {
     "duration": 36.122254,
     "end_time": "2021-03-10T13:16:49.075937",
     "exception": false,
     "start_time": "2021-03-10T13:16:12.953683",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/people/erikie/.local/lib/python3.6/site-packages/esm/pretrained.py:112: UserWarning: Regression weights not found, predicting contacts will not produce correct results.\n",
      "  warnings.warn(\"Regression weights not found, predicting contacts will not produce correct results.\")\n"
     ]
    }
   ],
   "source": [
    "# load 34 layer model\n",
    "model_path = \"../../models/esm1b_t33_650M_UR50S.pt\"\n",
    "\n",
    "model, alphabet = esm.pretrained.load_model_and_alphabet_local(model_path)\n",
    "batch_converter = alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ongoing-feelings",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T13:16:49.247396Z",
     "iopub.status.busy": "2021-03-10T13:16:49.246974Z",
     "iopub.status.idle": "2021-03-10T13:16:49.255969Z",
     "shell.execute_reply": "2021-03-10T13:16:49.256285Z"
    },
    "papermill": {
     "duration": 0.164477,
     "end_time": "2021-03-10T13:16:49.256391",
     "exception": false,
     "start_time": "2021-03-10T13:16:49.091914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Try to move model to GPU if possible\n",
    "try:\n",
    "    model = model.to(device)\n",
    "except RuntimeError:\n",
    "    device = 'cpu'\n",
    "    model = model.to(device)\n",
    "    \n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-sunday",
   "metadata": {
    "papermill": {
     "duration": 0.021741,
     "end_time": "2021-03-10T13:16:49.292258",
     "exception": false,
     "start_time": "2021-03-10T13:16:49.270517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Convert the sequences to batch tokens then to token embeddings: https://github.com/facebookresearch/esm/issues/21\n",
    "\n",
    "Since the pretrained models only is able todo embeddings with max 1024 residues, then an overlap method is implemented to concatenate the longer sequences. Thus, if a sequence is larger than 1024 residues, then the next iter of residues are concatenated by overlapping X residues which then takes X/2 from both of the concatenating sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alternative-nightmare",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T13:16:49.333099Z",
     "iopub.status.busy": "2021-03-10T13:16:49.332695Z",
     "iopub.status.idle": "2021-03-10T13:16:49.334545Z",
     "shell.execute_reply": "2021-03-10T13:16:49.334204Z"
    },
    "papermill": {
     "duration": 0.023972,
     "end_time": "2021-03-10T13:16:49.334626",
     "exception": false,
     "start_time": "2021-03-10T13:16:49.310654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def overlap_method(data, max_embedding = 1024, offset = 200, batches = 30):\n",
    "    # prepare data\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "    # calculate how many iterations for the overlaps\n",
    "    sequence_iter = math.floor(batch_tokens.shape[1]/max_embedding)\n",
    "    sequence_iter = math.floor((max_embedding*(sequence_iter+1)+offset*sequence_iter)/max_embedding)\n",
    "    \n",
    "    # extract sequences in batches to avoid RAM issues\n",
    "    result = torch.tensor([])\n",
    "    \n",
    "    for batch in range(0, batch_tokens.shape[0], batches):\n",
    "        # extract per-residue embeddings (on CPU)\n",
    "        batch_result = None\n",
    "        for i in range(sequence_iter):\n",
    "            embedding = None\n",
    "            with torch.no_grad():\n",
    "                if i == 0:\n",
    "                    # no overlap on first iter\n",
    "                    tmp_embedding = batch_tokens[batch:batch+batches, i:max_embedding+i]\n",
    "                    embedding = model(tmp_embedding.to(device), repr_layers=[33])[\"representations\"][33].cpu()\n",
    "                else:\n",
    "                    tmp_embedding = batch_tokens[batch:batch+batches, (max_embedding*i-offset*i):(max_embedding*(i+1)-offset*i)]\n",
    "                    embedding = model(tmp_embedding.to(device), repr_layers=[33])[\"representations\"][33].cpu()\n",
    "                    \n",
    "                    # concatenate by overlap for > max_embedding sequences\n",
    "                    overlap = int(offset/2)\n",
    "                    embedding = torch.cat([batch_result[:, :-overlap, :], embedding[:, overlap:, :]], dim=1)\n",
    "                    \n",
    "                batch_result = embedding\n",
    "            \n",
    "        # concatenate finished sequences\n",
    "        result = torch.cat([result, batch_result], dim=0)\n",
    "            \n",
    "        print(\"Finished embedding batch {} of {}\".format(batch+batches, batch_tokens.shape[0]))\n",
    "\n",
    "    # add extrapolated zeros\n",
    "    for idx_seq in range(len(batch_strs)):\n",
    "        result[idx_seq, len(batch_strs[idx_seq]):, :] = 0\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-monitoring",
   "metadata": {
    "papermill": {
     "duration": 0.015453,
     "end_time": "2021-03-10T13:16:49.366518",
     "exception": false,
     "start_time": "2021-03-10T13:16:49.351065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Save embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-affairs",
   "metadata": {
    "papermill": {
     "duration": 0.014846,
     "end_time": "2021-03-10T13:16:49.398265",
     "exception": false,
     "start_time": "2021-03-10T13:16:49.383419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The embeddings are merged with the labels from the original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prompt-highlight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T13:16:49.433113Z",
     "iopub.status.busy": "2021-03-10T13:16:49.432718Z",
     "iopub.status.idle": "2021-03-10T13:16:49.435151Z",
     "shell.execute_reply": "2021-03-10T13:16:49.435476Z"
    },
    "papermill": {
     "duration": 0.02177,
     "end_time": "2021-03-10T13:16:49.435571",
     "exception": false,
     "start_time": "2021-03-10T13:16:49.413801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_embedding(name, dataset):\n",
    "    # create embedding\n",
    "    result = overlap_method(sparse_to_sequence(dataset['data']))\n",
    "    \n",
    "    dataset = torch.tensor(dataset['data'])\n",
    "    \n",
    "    #remove start and end token\n",
    "    result = result[:-1, 1:result.shape[1]-1, :]\n",
    "    \n",
    "    #merge labels from original dataset and save\n",
    "    result = torch.cat([dataset, result], dim=2).numpy()\n",
    "    np.savez_compressed(data_dir.replace(\"nsp2\", \"nsp3\") + \"esm1b_\" + name + \".npz\", data=result)\n",
    "    \n",
    "    print(name + \" saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-healthcare",
   "metadata": {
    "papermill": {
     "duration": 0.021789,
     "end_time": "2021-03-10T13:16:49.471605",
     "exception": false,
     "start_time": "2021-03-10T13:16:49.449816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Add embeddings to datasets and save to file**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-stations",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ready-nothing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-10T13:16:49.512436Z",
     "iopub.status.busy": "2021-03-10T13:16:49.512041Z",
     "iopub.status.idle": "2021-03-10T15:12:59.787939Z",
     "shell.execute_reply": "2021-03-10T15:12:59.781951Z"
    },
    "papermill": {
     "duration": 6970.30493,
     "end_time": "2021-03-10T15:12:59.794866",
     "exception": true,
     "start_time": "2021-03-10T13:16:49.489936",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 30 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 60 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 90 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 120 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 150 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 180 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 210 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 240 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 270 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 300 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 330 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 360 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 390 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 420 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 450 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 480 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 510 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 540 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 570 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 600 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 630 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 660 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 690 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 720 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 750 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 780 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 810 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 840 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 870 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 900 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 930 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 960 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 990 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 1020 of 1001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_hhblits saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished embedding batch 30 of 22\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Got 1494 and 1632 in dimension 1 (The offending index is 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2f65d1a8fc41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0madd_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-17743a090bd2>\u001b[0m in \u001b[0;36madd_embedding\u001b[0;34m(name, dataset)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#merge labels from original dataset and save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavez_compressed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nsp2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nsp3\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"esm1b_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Got 1494 and 1632 in dimension 1 (The offending index is 1)"
     ]
    }
   ],
   "source": [
    "for name, data in datasets:\n",
    "    add_embedding(name, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-economics",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7013.539036,
   "end_time": "2021-03-10T15:13:01.225213",
   "environment_variables": {},
   "exception": true,
   "input_path": "embeddings_esm.ipynb",
   "output_path": "embeddings_esm.ipynb",
   "parameters": {
    "data_dir": "/home/projects/ht3_aim/people/erikie/NSPThesis/data/nsp2/training_data",
    "model_path": "/home/projects/ht3_aim/people/erikie/NSPThesis/models/esm1b_t33_650M_UR50S.pt"
   },
   "start_time": "2021-03-10T13:16:07.686177",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}