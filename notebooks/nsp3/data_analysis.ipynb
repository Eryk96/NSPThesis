{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "given-darkness",
   "metadata": {},
   "source": [
    "# Data analysis of the HHBLITS and MMSeqs datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-glory",
   "metadata": {},
   "source": [
    "First of all, the sequence lengths of the datasets are inspected, since the ESM1b embeddings works with residue sequences that are below 1024 and 500."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-consciousness",
   "metadata": {},
   "source": [
    "**Loading of libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sorted-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-conducting",
   "metadata": {},
   "source": [
    "## Loading dataset(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "average-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhblits = np.load('/home/eryk/development/NSPThesis/data/nsp2/training_data/Train_HHblits.npz')['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-creek",
   "metadata": {},
   "source": [
    "## Sequence length distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-aluminum",
   "metadata": {},
   "source": [
    "Count the sequences and then plot the distribution as a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "twelve-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sequences(data):\n",
    "    \"\"\"Counts the sequences in given data\"\"\"\n",
    "    hist = {}\n",
    "    for seq in data:\n",
    "        idx = sum(seq)\n",
    "        hist[idx] = hist.get(idx, 0) + 1\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "silent-frequency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot hhblits\n",
    "plt.style.use('science')\n",
    "\n",
    "hhblits_count = count_sequences(hhblits[:, :, 50])\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=(5, 5)\n",
    "n, bins, patches = plt.hist(x=hhblits_count, bins='auto')\n",
    "plt.xlabel('Sequence length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Train sequence length distribution')\n",
    "plt.axvline(x=1024, label='ESM1b input', c='y')\n",
    "plt.axvline(x=500, label='Uniform', c='r')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-pathology",
   "metadata": {},
   "source": [
    "**How many sequences are removed if lengths are reduced to only keep below 1024 and 600?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prostate-montgomery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 10848\n",
      "<1024: 34\n",
      "<500: 782\n"
     ]
    }
   ],
   "source": [
    "total = sum(hhblits_count.values())\n",
    "\n",
    "# lamda filter that filters out the keys\n",
    "filter_total = lambda x, y: dict([ (i,x[i]) for i in x if i < y ])\n",
    "\n",
    "# count if the sequences are reduced\n",
    "reduce_1024 = sum(filter_total(hhblits_count, 1024).values())\n",
    "reduce_500 = sum(filter_total(hhblits_count, 500).values())\n",
    "\n",
    "print(\"total:\", total)\n",
    "print(\"<1024:\", total-reduce_1024)\n",
    "print(\"<500:\", total-reduce_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "oriental-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhblits = hhblits[np.sum(hhblits[:, :, 50], axis=1) < 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acceptable-intranet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10066, 1632, 68)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hhblits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dental-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"/home/eryk/development/NSPThesis/data/nsp2/training_data/Train_HHblits_500.npz\", data=hhblits[:, :500, :])\n",
    "np.savez_compressed(\"/home/eryk/development/NSPThesis/data/nsp2/training_data/Train_HHblits_500_small.npz\", data=hhblits[:1000, :500, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-archives",
   "metadata": {},
   "source": [
    "## Split embedding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "several-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pdb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "packed-cooperative",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/home/eryk/development/NSPThesis/data/nsp3/training_data/Train_HHBlits_ESM1b.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e6721e3323d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/eryk/development/NSPThesis/data/nsp3/training_data/Train_HHBlits_ESM1b.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_residues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nsp3/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[1;32m    443\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    444\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[0;32m~/anaconda3/envs/nsp3/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/home/eryk/development/NSPThesis/data/nsp3/training_data/Train_HHBlits_ESM1b.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "f = h5py.File(\"/home/eryk/development/NSPThesis/data/nsp3/training_data/Train_HHBlits_ESM1b.hdf5\", \"r\")[\"dataset\"]\n",
    "f_sequences, f_residues, f_classes = f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-extension",
   "metadata": {},
   "source": [
    "**Lets create a dataset where we reduce to only include below 500 residues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "square-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 250\n",
    "max_residues = 500\n",
    "\n",
    "with h5py.File(\"/home/eryk/development/NSPThesis/data/nsp3/training_data/Train_HHBlits_ESM1b_500.hdf5\", \"w\") as f2:\n",
    "    dataset = f2.create_dataset(\"dataset\", (1, max_residues, f_classes), maxshape=(None, max_residues, f_classes), dtype='float64', compression=\"gzip\")\n",
    "        \n",
    "    n = 0\n",
    "    for sequences in range(0, f_sequences, batch):\n",
    "        \n",
    "        # retrieve and filter sequences\n",
    "        data = f[sequences:sequences+batch]\n",
    "        data = data[np.sum(data[:, :, 50], axis=1) < max_residues]\n",
    "        \n",
    "        # expand dataset dimension\n",
    "        data_sequences = data.shape[0]\n",
    "        dataset.resize((n+data_sequences, max_residues, f_classes))\n",
    "        \n",
    "        # save the filtered data\n",
    "        dataset[n:n+data_sequences] = data[:data_sequences, :max_residues]\n",
    "        \n",
    "        n += data_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-simpson",
   "metadata": {},
   "source": [
    "**Create small subsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vietnamese-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"/home/eryk/development/NSPThesis/data/nsp3/training_data/Train_HHBlits_ESM1b.hdf5\", \"r\")[\"dataset\"]\n",
    "\n",
    "with h5py.File(\"/home/eryk/development/NSPThesis/data/nsp3/training_data/Train_HHBlits_ESM1b_S.hdf5\", \"w\") as f2:\n",
    "    dataset = f2.create_dataset(\"dataset\", (200, f.shape[1], f.shape[2]), dtype='float64', compression=\"gzip\")\n",
    "    dataset[:200] = f[:200]\n",
    "\n",
    "f = h5py.File(\"/home/eryk/development/NSPThesis/data/nsp3/training_data/Train_HHBlits_ESM1b_500.hdf5\", \"r\")[\"dataset\"]\n",
    "\n",
    "with h5py.File(\"/home/eryk/development/NSPThesis/data/nsp3/training_data/Train_HHBlits_ESM1b_500_S.hdf5\", \"w\") as f2:\n",
    "    dataset = f2.create_dataset(\"dataset\", (200, f.shape[1], f.shape[2]), dtype='float64', compression=\"gzip\")\n",
    "    dataset[:200] = f[:200]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "leading-madrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00787175  0.05809084 -0.02836424 ...  0.1666221  -0.44573057\n",
      "  -0.20741236]\n",
      " [ 0.05949696 -0.05585581 -0.18400535 ... -0.03884577 -0.15477931\n",
      "   0.33799493]\n",
      " [-0.06148477  0.10019163  0.07873724 ...  0.16803379 -0.14928876\n",
      "   0.25068259]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(\"/home/eryk/development/NSPThesis/data/nsp3/training_data/Train_HHblits_ESM1b.hdf5\", \"r\")[\"dataset\"]\n",
    "print(f[0, :, 68:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "partial-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monetary-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_TRANSLATE = {\n",
    "    0: \"X\",\n",
    "    1: \"A\",\n",
    "    2: \"C\",\n",
    "    3: \"D\",\n",
    "    4: \"E\",\n",
    "    5: \"F\",\n",
    "    6: \"G\",\n",
    "    7: \"H\",\n",
    "    8: \"I\",\n",
    "    9: \"K\",\n",
    "    10: \"L\",\n",
    "    11: \"M\",\n",
    "    12: \"N\",\n",
    "    13: \"P\",\n",
    "    14: \"Q\",\n",
    "    15: \"R\",\n",
    "    16: \"S\",\n",
    "    17: \"T\",\n",
    "    18: \"V\",\n",
    "    19: \"W\",\n",
    "    20: \"Y\",\n",
    "}\n",
    "\n",
    "\n",
    "class ESM1bEmbedding(nn.Module):\n",
    "    \"\"\" ESM1b embedding layer module \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str, ft_embed_tokens: bool = False, ft_transformer: bool = False, ft_contact_head: bool = False, \n",
    "                 ft_embed_positions: bool = False, ft_emb_layer_norm_before: bool = False, ft_emb_layer_norm_after: bool = False, ft_lm_head: bool = False, max_embedding: int = 1024, offset: int = 200):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            model_path: path to language model\n",
    "            max_embeddings: maximum sequence length for language model\n",
    "            offset: overlap offset when concatenating sequences above max embedding\n",
    "        \"\"\"\n",
    "        super(ESM1bEmbedding, self).__init__()\n",
    "\n",
    "        # configure pre-trained model\n",
    "        self.model, alphabet = esm.pretrained.load_model_and_alphabet_local(model_path)\n",
    "        self.batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "        self.max_embedding = max_embedding\n",
    "        self.offset = offset\n",
    "        \n",
    "        # finetuning, freezes all layers by default\n",
    "        self.finetune = [ft_embed_tokens, ft_transformer, ft_contact_head, ft_embed_positions, ft_emb_layer_norm_before, ft_emb_layer_norm_after, ft_lm_head]\n",
    "        self._finetune()\n",
    "            \n",
    "    def _finetune(self):\n",
    "        # finetune by freezing unchoosen layers\n",
    "        print(\"finetune\")\n",
    "        for i, child in enumerate(self.model.children()):\n",
    "            if self.finetune[i] == False:\n",
    "                print(child)\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def _decode_sparse_encoding(self, x: torch.tensor) -> list:\n",
    "        # get sparse positions\n",
    "        x = (torch.argmax(x[:, :, :20], axis=2) + 1) * torch.amax(x[:, :, :20], axis=2)\n",
    "\n",
    "        sequences = []\n",
    "\n",
    "        # decode sparse encoding to residue sequence\n",
    "        batches = x.shape[0]\n",
    "        for i in range(batches):\n",
    "            sequence = \"\".join(map(lambda r: AA_TRANSLATE[r.item()], x[i])).rstrip(\"X\")\n",
    "            sequences.append((\"protein_\" + str(i), sequence))\n",
    "\n",
    "        return sequences\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        device = x.device\n",
    "        sequence_length = x.shape[1]\n",
    "\n",
    "        x = self._decode_sparse_encoding(x)\n",
    "\n",
    "        # make tokens and move to cude if possible\n",
    "        batch_labels, batch_strs, batch_tokens = self.batch_converter(x)\n",
    "        batch_tokens = batch_tokens.to(device)\n",
    "        batch_sequences, batch_residues = batch_tokens.shape\n",
    "\n",
    "        embedding = self.model(batch_tokens[:, :self.max_embedding], repr_layers=[33])[\"representations\"][33]\n",
    "            \n",
    "        # if size above 1024 then generate embeddings that overlaps with the offset\n",
    "        if batch_residues >= self.max_embedding:\n",
    "            # combine by overlaps\n",
    "            for i in range(1, math.floor(batch_residues / self.max_embedding) + 1):\n",
    "                o1 = (self.max_embedding - self.offset) * i\n",
    "                o2 = o1 + self.max_embedding\n",
    "                embedding = torch.cat([embedding[:, :o1], self.model(\n",
    "                    batch_tokens[:, o1:o2], repr_layers=[33])[\"representations\"][33]], dim=1)\n",
    "            embedding = torch.nan_to_num(embedding)\n",
    "\n",
    "        # add padding\n",
    "        embedding = F.pad(embedding, pad=(0, 0, 0, sequence_length-embedding.shape[1]), mode='constant', value=0)\n",
    "    \n",
    "        # cleanup\n",
    "        del batch_tokens\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interested-ghana",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eryk/anaconda3/envs/nsp3/lib/python3.8/site-packages/esm/pretrained.py:112: UserWarning: Regression weights not found, predicting contacts will not produce correct results.\n",
      "  warnings.warn(\"Regression weights not found, predicting contacts will not produce correct results.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune\n",
      "ModuleList(\n",
      "  (0): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (1): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (2): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (3): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (4): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (5): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (6): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (7): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (8): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (9): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (10): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (11): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (12): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (13): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (14): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (15): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (16): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (17): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (18): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (19): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (20): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (21): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (22): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (23): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (24): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (25): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (26): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (27): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (28): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (29): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (30): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (31): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (32): TransformerLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "      (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    )\n",
      "    (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "    (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "    (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "ContactPredictionHead(\n",
      "  (regression): Linear(in_features=660, out_features=1, bias=True)\n",
      "  (activation): Sigmoid()\n",
      ")\n",
      "LearnedPositionalEmbedding(1026, 1280, padding_idx=1)\n",
      "LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "RobertaLMHead(\n",
      "  (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "  (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ESM1bEmbedding(\"/home/eryk/development/NSPThesis/models/esm1b_t33_650M_UR50S.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "multiple-property",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESM1bEmbedding(\n",
       "  (model): ProteinBertModel(\n",
       "    (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (12): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (13): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (14): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (15): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (16): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (17): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (18): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (19): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (20): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (21): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (22): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (23): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (24): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (25): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (26): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (27): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (28): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (29): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (30): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (31): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (32): TransformerLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (contact_head): ContactPredictionHead(\n",
       "      (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (embed_positions): LearnedPositionalEmbedding(1026, 1280, padding_idx=1)\n",
       "    (emb_layer_norm_before): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_head): RobertaLMHead(\n",
       "      (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assumed-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0252,  0.2534,  0.1238,  ...,  0.0311,  0.0084, -0.0639],\n",
      "         [ 0.0079,  0.0581, -0.0284,  ...,  0.1666, -0.4457, -0.2074],\n",
      "         [ 0.0595, -0.0559, -0.1840,  ..., -0.0388, -0.1548,  0.3380],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model(torch.tensor(f[0, :, :20]).unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "imperial-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0252,  0.2534,  0.1238,  ...,  0.0311,  0.0084, -0.0639],\n",
      "         [ 0.0079,  0.0581, -0.0284,  ...,  0.1666, -0.4457, -0.2074],\n",
      "         [ 0.0595, -0.0559, -0.1840,  ..., -0.0388, -0.1548,  0.3380],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.1430,  0.1740,  0.1948,  ...,  0.1256,  0.0091, -0.0543],\n",
      "         [-0.0634, -0.0551,  0.5158,  ..., -0.1531,  0.1662, -0.2550],\n",
      "         [ 0.2619, -0.1102,  0.0700,  ...,  0.0500,  0.1526,  0.0623],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model(torch.tensor(f[:2, :, :20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-celtic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
